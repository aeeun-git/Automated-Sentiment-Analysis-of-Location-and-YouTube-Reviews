{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb41e09f-46bf-4ad7-ad28-a7d16950ccdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dosl1\\anaconda3\\envs\\homework\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab9c376-9759-4122-ac5d-651a0c7256a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ íŒŒì¼ ê²½ë¡œ: data/aihub\\Sample\\02.ë¼ë²¨ë§ë°ì´í„°\\SNS\\01. íŒ¨ì…˜\\1-1.ì—¬ì„±ì˜ë¥˜(196).json\n",
      "\n",
      "--- [JSON ë‚´ë¶€ êµ¬ì¡° í™•ì¸] ---\n",
      "[\n",
      "  {\n",
      "    \"Index\": \"1024338\",\n",
      "    \"RawText\": \"ì•ˆë…•í•˜ì„¸ìš” ì´ì›ƒë‹˜ë“¤ ë°˜ê°‘ìŠµë‹ˆë‹¤. ìš”ì¦˜ ë‚ ì”¨ê°€ ë§ì´ ìŒ€ìŒ€í•´ì¡Œì£ ? ìš”ì¦˜ ê³„ì ˆì— ì…ìœ¼ë©´ ë”± ì¢‹ì„ ì¸ìƒ ê²½ëŸ‰ íŒ¨ë”© í•˜ë‚˜ ì†Œê°œí•´ ë“œë¦´ê²Œìš”.  ë‹¤ í•¨ê»˜ go go go~~  ì œê°€ ì…ì–´ë³´ê³  ì¢‹ì•„ì„œ ì—„ë§ˆê»˜ë„ êµ¬ë§¤í•´ë“œë ¸ë„¤ìš”. ë”± ê¸°ë³¸ ìŠ¤íƒ€ì¼ì¸ë° ë˜ ì…ì€ ê±° ë³´ë©´ ê¹”ë”í•˜ê²Œ ì €ë ´í•´ë³´ì´ì§€ ì•ŠëŠ” ë””ìì¸ì´ë¼ì„œ ì–´ë””ì„œ ìƒ€ëƒê³  ë§ì´ë“¤ ë¬¼ì–´ë³´ëŠ” ì˜·ì…ë‹ˆë‹¤.  ì—„ë§ˆë„ ì œê°€ ì…ì€ ê²ƒ ë³´ì‹œë”ë‹ˆ íƒë‚´ì…”ì„œ  ì£¼ë¬¸í•´ë“œë ¸ì–´ìš”. ì˜í•˜ë¡œ ë‚´ë ¤ê°€ëŠ” ë‚ ì”¨ì—ëŠ” ì´ê²ƒë§Œ ì…ê¸°ì—” ì–‡ì§€ë§Œ ì´ˆê²¨ìš¸ê¹Œì§€ëŠ” ìš´ë™ ê°ˆë•Œ ì•ˆì— ì–‡ì€ ê¸°ëŠ¥ì„± ë°˜íŒ” ì…ê³  ìš”ê²ƒë§Œ ì…ì–´ë„ ê½¤ ë”°ëœ»í•´ìš”. ìƒ‰ìƒë„ ë””ìì¸ë„ ë¬´ë‚œí•´ì„œ ì‚¬ë¬´ì‹¤ì— ë‘ê³  ì…ê¸°ë„ ì¢‹ê³ , í‰ì†Œì— ê°€ë³ê²Œ ë‚˜ê°ˆë•Œ ì½”ë””í•˜ê¸°ë„ ì¢‹ì•„ìš”. ì•ìœ¼ë¡œ ì½”íŠ¸ë¥¼ ì…ê±°ë‚˜ í• ë•Œ ì•ˆì— ë‚´í”¼ë¡œ í™œìš©í•˜ê¸°ë„ ë”±ì¼ ë“¯ìš”! ë§˜ê°™ì•„ì„  ìƒ‰ê¹”ë³„ë¡œ ìŸì´ê³  ì‹¶ìŠµë‹ˆë‹¤.  20ëŒ€ì™€ 50ëŒ€ ëª¨ë‘ ì•„ìš°ë¥´ëŠ” ë””ìì¸ì´ ë¬´ë‚œí•˜ê³  ê¹”ë”í•˜ë©´ì„œ ê³ ê¸‰ìŠ¤ëŸ¬ìš´ ì˜· ì¶”ì²œí•©ë‹ˆë‹¤~~~  ì„¤ëª… ë! ì¢€ ë„ì›€ì´ ë˜ì…¨ë‚˜ìš”? ê·¸ëŸ¬ë©´ ì¢‹ì•„ìš” ê¾¹ ëˆŒëŸ¬ ì£¼ì‹œê³  ì „ ì´ë§Œ ì´ì´ì´~~ í•­ìƒ ì—¬ëŸ¬ ì´ì›ƒë‹˜ë“¤ê»˜ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. \",\n",
      "    \"Source\": \"SNS\",\n",
      "    \"Domain\": \"íŒ¨ì…˜\",\n",
      "    \"MainCategory\": \"ì—¬ì„±ì˜ë¥˜\",\n",
      "    \"ProductName\": \"OO ê²½ëŸ‰ ë‹¤ìš´ ìì¼“\",\n",
      "    \"Syllable\": \"513\",\n",
      "    \"Word\": \"121\",\n",
      "    \"GeneralPolarity\": \"1\",\n",
      "    \"Aspects\": [\n",
      "      {\n",
      "        \"Aspect\": \"ë””ìì¸\",\n",
      "        \"SentimentText\": \"ë”± ê¸°ë³¸ ìŠ¤íƒ€ì¼ì¸ë° ë˜ ì…ì€ ê±° ë³´ë©´ ê¹”ë”í•˜ê²Œ ì €ë ´í•´ë³´ì´ì§€ ì•ŠëŠ” ë””ìì¸ì´ë¼ì„œ\",\n",
      "        \"SentimentWord\": \"11\",\n",
      "        \"SentimentPolarity\": \"1\"\n",
      "      },\n",
      "      {\n",
      "        \"Aspect\": \"ë‘ê»˜\",\n",
      "        \"SentimentText\": \"ì´ê²ƒë§Œ ì…ê¸°ì—” ì–‡ì§€ë§Œ\",\n",
      "\n",
      "-----------------------------\n",
      "ìœ„ ì¶œë ¥ ê²°ê³¼ì—ì„œ 'ë¦¬ë·° ë‚´ìš©'ê³¼ 'ê°ì • ë¼ë²¨'ì´ ì–´ë–¤ ì˜ì–´ ë‹¨ì–´(Key)ë¡œ ë˜ì–´ìˆëŠ”ì§€ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "# ì•„ê¹Œ íŒŒì¼ ì°¾ê¸°ì— ì„±ê³µí–ˆë˜ ê·¸ ê²½ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "ROOT_PATH = \"data/aihub/**/*.json\"\n",
    "\n",
    "file_list = glob.glob(ROOT_PATH, recursive=True)\n",
    "\n",
    "if len(file_list) > 0:\n",
    "    # ì²« ë²ˆì§¸ íŒŒì¼ë§Œ ë”± êº¼ë‚´ì„œ ì—½ë‹ˆë‹¤\n",
    "    target_file = file_list[0]\n",
    "    print(f\"ğŸ“‚ íŒŒì¼ ê²½ë¡œ: {target_file}\")\n",
    "    \n",
    "    with open(target_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    print(\"\\n--- [JSON ë‚´ë¶€ êµ¬ì¡° í™•ì¸] ---\")\n",
    "    # ë³´ê¸° ì¢‹ê²Œ ë“¤ì—¬ì“°ê¸°í•´ì„œ ì¶œë ¥ (ì•ë¶€ë¶„ 1000ìë§Œ)\n",
    "    print(json.dumps(data, indent=2, ensure_ascii=False)[:1000]) \n",
    "    \n",
    "    print(\"\\n-----------------------------\")\n",
    "    print(\"ìœ„ ì¶œë ¥ ê²°ê³¼ì—ì„œ 'ë¦¬ë·° ë‚´ìš©'ê³¼ 'ê°ì • ë¼ë²¨'ì´ ì–´ë–¤ ì˜ì–´ ë‹¨ì–´(Key)ë¡œ ë˜ì–´ìˆëŠ”ì§€ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"âŒ ê²½ë¡œì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd228420-ec33-43c1-be50-bf5932a33038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” 'data/aihub/**/*.json' ê²½ë¡œì—ì„œ íŒŒì¼ ê²€ìƒ‰ ì¤‘...\n",
      "âœ… ê²€ìƒ‰ëœ ì „ì²´ íŒŒì¼ ìˆ˜: 2385ê°œ\n",
      "ğŸ² íŒŒì¼ ëª©ë¡ì„ ë¬´ì‘ìœ„ë¡œ ì„ëŠ” ì¤‘...\n",
      "ğŸš€ ìƒìœ„ 15000ê°œ íŒŒì¼ì—ì„œ ë°ì´í„° ì¶”ì¶œ ì‹œì‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–Š         | 206/2385 [00:00<00:03, 597.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ ìµœì¢… ìˆ˜ì§‘ ì™„ë£Œ: 15023ê°œ\n",
      "\n",
      "--- [ë°ì´í„° ìƒ˜í”Œ] ---\n",
      "                                                    text  label\n",
      "7830   í—ˆë¸Œ í–¥ ì“°ë‹¤ê°€ ì²˜ìŒ ì“°ëŠ” í–¥ì¸ë° ì¢‹ì•„í•˜ëŠ” í–¥ì€ ì•„ë‹ˆë¼ ì¢€ ì‹¤ë§ì…ë‹ˆë‹¤.  ê·¸ëƒ¥ì €ëƒ¥ ...      0\n",
      "10870  ë””ìì¸ ì‹¬í”Œí•˜ë‹ˆ ì„¸ë ¨ë˜ê³  ê´œì°®ë„¤ìš”  ì‚¬ì´ì¦ˆë„ íƒœë¸”ë¦¿ìœ¼ë¡œ íœ´ëŒ€ì„±ì„ ìµœëŒ€í•œ ë°œíœ˜í•˜ë©° ì‚¬...      1\n",
      "1027   ì´ ì œí’ˆì€ ooo ì‹œê·¸ë‹ˆì²˜ í–¥ì´ë¼ ìµìˆ™í•´ì„œ ì¢‹ì•˜ìŠµë‹ˆë‹¤. ë§¤ì¥ì— ë“¤ì–´ê°€ë©´ ë§¡ì„ ìˆ˜ ìˆ...      1\n",
      "8725   ë™ìƒì´ ì¢‹ë‹¤ê³  í•´ì„œ ì£¼ë¬¸í•´ ë´¤ëŠ”ë° ë¨¸ë¦¬ì— ë–¡ ì•ˆ ì§€ê³  ìì—°ìŠ¤ëŸ½ê²Œ ê³ ì •ë©ë‹ˆë‹¤. ì†Œí”„íŠ¸...      1\n",
      "213    ì‹¤ë¦¬ì½˜ì´ë¼ í° ëƒ„ë¹„ì—ë„ ì‘ì€ ëƒ„ë¹„ì—ë„ ì˜ ë§ê³  ì°œê¸°ì— ìŒì‹ë¬¼ì´ ë“¤ëŸ¬ ë¶™ì§€ ì•Šì•„ì„œ í¸...      1\n",
      "\n",
      "--- [ë¼ë²¨ ë¶„í¬] ---\n",
      "label\n",
      "1    12357\n",
      "0     2666\n",
      "Name: count, dtype: int64\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import random \n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. ì„¤ì • (ì´ ë¶€ë¶„ì€ ê·¸ëŒ€ë¡œ ë‘ì„¸ìš”)\n",
    "# ==========================================\n",
    "ROOT_PATH = \"data/aihub/**/*.json\"\n",
    "TARGET_COUNT = 15000 \n",
    "\n",
    "# âœ… ì°¾ì€ í‚¤ ì´ë¦„ìœ¼ë¡œ ìˆ˜ì • ì™„ë£Œ!\n",
    "KEY_TEXT = \"RawText\"           \n",
    "KEY_LABEL = \"GeneralPolarity\"  \n",
    "# ==========================================\n",
    "\n",
    "print(f\"ğŸ” '{ROOT_PATH}' ê²½ë¡œì—ì„œ íŒŒì¼ ê²€ìƒ‰ ì¤‘...\")\n",
    "all_files = glob.glob(ROOT_PATH, recursive=True)\n",
    "\n",
    "if len(all_files) == 0:\n",
    "    print(\"âŒ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(f\"âœ… ê²€ìƒ‰ëœ ì „ì²´ íŒŒì¼ ìˆ˜: {len(all_files)}ê°œ\")\n",
    "\n",
    "    print(\"ğŸ² íŒŒì¼ ëª©ë¡ì„ ë¬´ì‘ìœ„ë¡œ ì„ëŠ” ì¤‘...\")\n",
    "    random.seed(42) \n",
    "    random.shuffle(all_files)\n",
    "\n",
    "    print(f\"ğŸš€ ìƒìœ„ {TARGET_COUNT}ê°œ íŒŒì¼ì—ì„œ ë°ì´í„° ì¶”ì¶œ ì‹œì‘...\")\n",
    "    \n",
    "    collected_data = []\n",
    "    success_count = 0\n",
    "\n",
    "    for file_path in tqdm(all_files):\n",
    "        if success_count >= TARGET_COUNT:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # ğŸ“Œ ì¤‘ìš”: ë°ì´í„°ê°€ ë¦¬ìŠ¤íŠ¸ [ ... ] í˜•íƒœì¸ ê²½ìš° ì²˜ë¦¬\n",
    "            # (ë°©ê¸ˆ ë³´ì—¬ì£¼ì‹  êµ¬ì¡°ê°€ ë¦¬ìŠ¤íŠ¸ì˜€ìŠµë‹ˆë‹¤)\n",
    "            if isinstance(data, list):\n",
    "                items = data\n",
    "            else:\n",
    "                items = [data] # ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ê¸°\n",
    "\n",
    "            for item in items:\n",
    "                text = item.get(KEY_TEXT)\n",
    "                org_label = str(item.get(KEY_LABEL)) # \"1\", \"-1\" ë“± ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "\n",
    "                # ğŸ“Œ ë¼ë²¨ ë³€í™˜ ë¡œì§ (AI Hub ì‡¼í•‘ ë°ì´í„° ê¸°ì¤€)\n",
    "                # \"1\" -> ê¸ì •(1)\n",
    "                # \"-1\" -> ë¶€ì •(0)\n",
    "                # \"0\" -> ì¤‘ë¦½ (í•™ìŠµì—ì„œ ì œì™¸)\n",
    "                \n",
    "                final_label = None\n",
    "                if org_label == \"1\":    # ê¸ì •\n",
    "                    final_label = 1\n",
    "                elif org_label == \"-1\": # ë¶€ì •\n",
    "                    final_label = 0\n",
    "                \n",
    "                # í…ìŠ¤íŠ¸ê°€ ìˆê³ , ê¸ì •/ë¶€ì •(1/0)ì´ í™•ì‹¤í•œ ê²½ìš°ë§Œ ì €ì¥\n",
    "                if text and final_label is not None:\n",
    "                    collected_data.append({'text': text, 'label': final_label})\n",
    "                    success_count += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue \n",
    "\n",
    "    # ì €ì¥\n",
    "    if collected_data:\n",
    "        df = pd.DataFrame(collected_data)\n",
    "        print(f\"\\nğŸ‰ ìµœì¢… ìˆ˜ì§‘ ì™„ë£Œ: {len(df)}ê°œ\")\n",
    "        print(\"\\n--- [ë°ì´í„° ìƒ˜í”Œ] ---\")\n",
    "        print(df.sample(5))\n",
    "        \n",
    "        # ê¸ì •/ë¶€ì • ë¹„ìœ¨ í™•ì¸\n",
    "        print(\"\\n--- [ë¼ë²¨ ë¶„í¬] ---\")\n",
    "        print(df['label'].value_counts())\n",
    "        \n",
    "        df.to_csv(\"aihub_shuffled_15k.csv\", index=False, encoding='utf-8-sig')\n",
    "        print(\"ğŸ’¾ ì €ì¥ ì™„ë£Œ!\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ ì—¬ì „íˆ ë°ì´í„°ê°€ 0ê°œì…ë‹ˆë‹¤. í‚¤ ì´ë¦„ì´ë‚˜ í´ë” êµ¬ì¡°ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2b0230-56b3-44f1-b341-8297d32ae007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
